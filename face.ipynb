{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "from pymongo import MongoClient\n",
    "# import face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UUID\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('b9a2ed64-80f3-491c-8b7b-610d1b8d4d1e')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Register(a,b):\n",
    "# Load the jpg file into a numpy array\n",
    "    path_reg =a \n",
    "    name = b\n",
    "    image = face_recognition.load_image_file(path_reg)\n",
    "    face_locations = face_recognition.face_locations(\n",
    "        image, number_of_times_to_upsample=0, model=\"cnn\")\n",
    "\n",
    "    print(\"Found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "\n",
    "    # for face_location in face_locations:\n",
    "\n",
    "    #     # Print the location of each face in this image\n",
    "    #     top, right, bottom, left = face_location\n",
    "    #     print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(\n",
    "    #         top, left, bottom, right))\n",
    "\n",
    "    #     # You can access the actual face itself like this:\n",
    "    #     face_image = image[top:bottom, left:right]\n",
    "    #     pil_image = Image.fromarray(face_image)\n",
    "    #     # pil_image.show()\n",
    "    #     k = pil_image.resize((250, 250))\n",
    "    #     Name = name\n",
    "    #     # path_store = '/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/{}.jpg'.format(\n",
    "    #     #     Name)\n",
    "    #     k.save(path_reg)\n",
    "    ID = uuid.uuid4()\n",
    "    dict1 = [{'name': name, 'ID': (str)(ID),\n",
    "                'image': path_reg}]\n",
    "    collection.insert(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 face(s) in this photograph.\n",
      "A face is located at pixel location Top: 0, Left: 0, Bottom: 250, Right: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-551916471e0e>:30: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  collection.insert(dict1)\n"
     ]
    }
   ],
   "source": [
    "Register('/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/aishwarya.jpg','Aishwarya')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MongoClient' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8d829a795dbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMongoClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'localhost'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m27017\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'faces-test2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MongoClient' is not defined"
     ]
    }
   ],
   "source": [
    "client = MongoClient('localhost',27017)\n",
    "db = client['faces-test2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db['faces3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-0209826b6bf6>:1: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  mydoc = collection.find().count()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydoc = collection.find().count()\n",
    "mydoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ID = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir('prototype_faces_s'):\n",
    "    for j in os.listdir(os.path.join('prototype_faces_s',i)):\n",
    "        im = Image.open('/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces_s/{}/{}'.format(i,j))\n",
    "        im2=im.resize((250,250))\n",
    "        img=im2.save('/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces_s/{}/image.jpg'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=0\n",
    "jj=0\n",
    "for i in os.listdir('prototype_faces_s'):\n",
    "    names.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('prototype_faces_s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir('prototype_faces_s'):\n",
    "    for j in os.listdir(os.path.join('prototype_faces_s',i)):\n",
    "        known_image = face_recognition.load_image_file('/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces_s/{}/{}'.format(i,j))\n",
    "        enc = face_recognition.face_encodings(known_image)[0]\n",
    "        encoding.append(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(encoding[1].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths=[]\n",
    "for i in os.listdir('prototype_faces_s'):\n",
    "    for j in os.listdir(os.path.join('prototype_faces_s',i)):\n",
    "        paths.append('/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces_s/{}/{}'.format(i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = 5\n",
    "#webcam_path='/Users/aishaandatt/Downloads/IIT_Temp/abhay3.jpeg'\n",
    "from PIL import Image\n",
    "webcam = face_recognition.load_image_file(\"/Users/aishaandatt/Downloads/IIT_Temp/abhay_web.jpg\")\n",
    "face_locations = face_recognition.face_locations(webcam, number_of_times_to_upsample=0, model=\"cnn\")\n",
    "for face_location in face_locations:\n",
    "    top, right, bottom, left = face_location\n",
    "    face_image = webcam[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    k=pil_image.resize((250,250))\n",
    "    namepath = 'face.jpg'\n",
    "    k.save('/Users/aishaandatt/Downloads/IIT_Temp/webcam-imgs/{}'.format(namepath))\n",
    "##webcam load and encode\n",
    "webcam_load=face_recognition.load_image_file('/Users/aishaandatt/Downloads/IIT_Temp/webcam-imgs/{}'.format(namepath))\n",
    "my_face_encoding = face_recognition.face_encodings(webcam)[0]\n",
    "x=(collection.find_one({'ID':IDs}))\n",
    "##db load and encode\n",
    "db_img=face_recognition.load_image_file(x['image'])\n",
    "db_enc = face_recognition.face_encodings(db_img)[0]\n",
    "results = face_recognition.compare_faces([my_face_encoding], db_enc)\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namepath = 'face.jpg'\n",
    "# webcam_path='/Users/aishaandatt/Downloads/IIT_Temp/abhay3.jpeg'\n",
    "from PIL import Image\n",
    "webcam = face_recognition.load_image_file('/Users/aishaandatt/Downloads/IIT_Temp/Tom-Hanks.jpeg')\n",
    "face_locations = face_recognition.face_locations(\n",
    "    webcam, number_of_times_to_upsample=0, model=\"cnn\")\n",
    "for face_location in face_locations:\n",
    "    top, right, bottom, left = face_location\n",
    "    face_image = webcam[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    k = pil_image.resize((250, 250))\n",
    "\n",
    "    k.save('/Users/aishaandatt/Downloads/IIT_Temp/webcam-imgs/{}'.format(namepath))\n",
    "# webcam load and encode\n",
    "webcam_load = face_recognition.load_image_file(\n",
    "    '/Users/aishaandatt/Downloads/IIT_Temp/webcam-imgs/{}'.format(namepath))\n",
    "my_face_encoding = face_recognition.face_encodings(webcam_load)[0]\n",
    "# db load and encode\n",
    "ctr=0\n",
    "for i in os.listdir('/Users/aishaandatt/Downloads/IIT_Temp/lfw_new'):\n",
    "    db_img = face_recognition.load_image_file((os.path.join('/Users/aishaandatt/Downloads/IIT_Temp/lfw_new', i)))\n",
    "    print((os.path.join('/Users/aishaandatt/Downloads/IIT_Temp/lfw_new', i)))\n",
    "    print(ctr)\n",
    "    ctr=ctr+1\n",
    "    db_enc = face_recognition.face_encodings(db_img)[0]\n",
    "    results = face_recognition.compare_faces([my_face_encoding], db_enc)\n",
    "    if(results[0] == True):\n",
    "        print('Yes')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "picture_of_me = face_recognition.load_image_file(\"/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/Aamir_Khan/0_7.jpg\")\n",
    "my_face_encoding = face_recognition.face_encodings(picture_of_me)[0]\n",
    "\n",
    "# my_face_encoding now contains a universal 'encoding' of my facial features that can be compared to any other picture of a face!\n",
    "\n",
    "unknown_picture = face_recognition.load_image_file(\"/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/Aamir_Khan/0_9.jpg\")\n",
    "unknown_face_encoding = face_recognition.face_encodings(unknown_picture)[0]\n",
    "\n",
    "# Now we can see the two face encodings are of the same person with `compare_faces`!\n",
    "\n",
    "results = face_recognition.compare_faces([my_face_encoding], unknown_face_encoding)\n",
    "\n",
    "if results[0] == True:\n",
    "    print(\"It's a picture of me!\")\n",
    "else:\n",
    "    print(\"It's not a picture of me!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_of_me = face_recognition.load_image_file(\"/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/Aamir_Khan/0_7.jpg\") #Consider this an input from webcam\n",
    "my_face_encoding = face_recognition.face_encodings(picture_of_me)[0]\n",
    "for i in os.listdir('prototype_faces'):\n",
    "    for j in os.listdir(os.path.join('prototype_faces',i)):\n",
    "        unknown_picture = face_recognition.load_image_file(os.path.join('prototype_faces',i,j))\n",
    "        unknown_face_encoding = face_recognition.face_encodings(unknown_picture)[0]\n",
    "        # Now we can see the two face encodings are of the same person with `compare_faces`!\n",
    "        results = face_recognition.compare_faces([my_face_encoding], unknown_face_encoding)\n",
    "    if results[0] == True:\n",
    "        print(\"It's a picture of me!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"It's not a picture of me!\")\n",
    "print(os.path.join(i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(\"/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/Jack_Straw_0002.jpg\")\n",
    "\n",
    "# Find all the faces in the image using a pre-trained convolutional neural network.\n",
    "# This method is more accurate than the default HOG model, but it's slower\n",
    "# unless you have an nvidia GPU and dlib compiled with CUDA extensions. But if you do,\n",
    "# this will use GPU acceleration and perform well.\n",
    "# See also: find_faces_in_picture.py\n",
    "face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\")\n",
    "\n",
    "print(\"Found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "\n",
    "for face_location in face_locations:\n",
    "\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = image[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()\n",
    "    k=pil_image.resize((250,250))\n",
    "    namepath = 'face2.jpg'\n",
    "    k.save('/Users/aishaandatt/Downloads/IIT_Temp/{}'.format(namepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathreg='/Users/aishaandatt/Downloads/IIT_Temp/{}'.format(namepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-fb2f01880173>:1: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
      "  db.collection.count()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/aamir.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/abhay.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/abhishek.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/aftab.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/aishwarya.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/ajay.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/akshay.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/ameesha.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/amrita.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/amy.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/anil.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/anushka_shetty.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/anushka.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/arjun_rampal.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/arjun.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/Aishaan.jpg\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/Taylor-Swift.jpeg\n"
     ]
    }
   ],
   "source": [
    "for coll_name in db.list_collection_names():\n",
    "    for r in db[coll_name].find({}):\n",
    "        print(r['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/aishaandatt/Downloads/IIT_Temp/Taylor-Swift.jpeg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1a0a886ab7a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mctr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'faces1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mctr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "ctr=0\n",
    "for r in db['faces1'].find({}):\n",
    "    ctr=ctr+1\n",
    "    print(r['image'])\n",
    "    print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/aamir.jpg\n",
      "1\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/abhay.jpg\n",
      "2\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/abhishek.jpg\n",
      "3\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/aftab.jpg\n",
      "4\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/aishwarya.jpg\n",
      "5\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/ajay.jpg\n",
      "6\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/akshay.jpg\n",
      "7\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/ameesha.jpg\n",
      "8\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/amrita.jpg\n",
      "9\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/amy.jpg\n",
      "10\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/anil.jpg\n",
      "11\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/anushka_shetty.jpg\n",
      "12\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/anushka.jpg\n",
      "13\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/arjun_rampal.jpg\n",
      "14\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/arjun.jpg\n",
      "15\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/Aishaan.jpg\n",
      "16\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/Taylor-Swift.jpeg\n",
      "17\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f4ccc31916e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdb_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ctr=0\n",
    "for r in db['faces1'].find({}):\n",
    "    ctr=ctr+1\n",
    "    db_img = face_recognition.load_image_file('{}'.format(r['image']))\n",
    "    print(r['image'])\n",
    "    print(ctr)\n",
    "    db_enc = face_recognition.face_encodings(db_img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verification2():\n",
    "    namepath = 'face.jpg'\n",
    "    # webcam_path='/Users/aishaandatt/Downloads/IIT_Temp/abhay3.jpeg'\n",
    "    from PIL import Image\n",
    "    path_img = '/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/abhay.jpg'\n",
    "    webcam = face_recognition.load_image_file('{}'.format(path_img))\n",
    "    face_locations = face_recognition.face_locations(\n",
    "        webcam, number_of_times_to_upsample=0, model=\"cnn\")\n",
    "    for face_location in face_locations:\n",
    "        top, right, bottom, left = face_location\n",
    "        face_image = webcam[top:bottom, left:right]\n",
    "        pil_image = Image.fromarray(face_image)\n",
    "        k = pil_image.resize((250, 250))\n",
    "        k.save('/Users/aishaandatt/Downloads/IIT_Temp/webcam-imgs/{}'.format(namepath))\n",
    "    # webcam load and encode\n",
    "    webcam_load = face_recognition.load_image_file(\n",
    "        '/Users/aishaandatt/Downloads/IIT_Temp/webcam-imgs/{}'.format(namepath))\n",
    "    my_face_encoding = face_recognition.face_encodings(webcam_load)[0]\n",
    "    # db load and encode\n",
    "    ctr = 0\n",
    "    for r in db['faces-id-cv-col'].find({}):\n",
    "        print(r['image'])\n",
    "        ctr = ctr+1\n",
    "        db_img = face_recognition.load_image_file('{}'.format(r['image']))\n",
    "        db_enc = face_recognition.face_encodings(db_img)[0]\n",
    "        # print(ctr, mydoc)\n",
    "        results = face_recognition.compare_faces(\n",
    "            [my_face_encoding], db_enc)\n",
    "        if(results[0] == True):\n",
    "            print(r['name'])\n",
    "            break\n",
    "        else:\n",
    "            print('False')\n",
    "    # if(results[0] == False):\n",
    "    #     Register()\n",
    "    print(ctr)\n",
    "\n",
    "    return results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/aamir.jpg\n",
      "False\n",
      "/Users/aishaandatt/Downloads/IIT_Temp/prototype_faces/abhay.jpg\n",
      "Abhay Deol\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verification2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d53b70d271a4bea04a667c0f9fbea9726ae2936282e68563ea6cd37a0552f713"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
