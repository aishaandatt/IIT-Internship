{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"%%writefile file.txt\\nThis is the first word.\\nThis is the second text, Hello! How are you?\\nThis is the third, this is it now.\\nThis is the algorithm enticed for hashing\\nHashing insn't performed linearly on large datasets.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('file.txt', encoding='utf8')\n",
    "read = file.read()\n",
    "file.seek(0)\n",
    "read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in file is:  6\n"
     ]
    }
   ],
   "source": [
    "line = 1\n",
    "for word in read:\n",
    "    if word == '\\n':\n",
    "        line += 1\n",
    "print(\"Number of lines in file is: \", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['%%writefile file.txt\\n',\n",
       " 'This is the first word.\\n',\n",
       " 'This is the second text, Hello! How are you?\\n',\n",
       " 'This is the third, this is it now.\\n',\n",
       " 'This is the algorithm enticed for hashing\\n',\n",
       " \"Hashing insn't performed linearly on large datasets.\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = []\n",
    "for i in range(line):\n",
    "    array.append(file.readline())\n",
    "  \n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  writefile file txt\\nThis is the first word \\nThis is the second text  Hello  How are you \\nThis is the third  this is it now \\nThis is the algorithm enticed for hashing\\nHashing insn t performed linearly on large datasets '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''\n",
    "for ele in read:  \n",
    "    if ele in punc:  \n",
    "        read = read.replace(ele, \" \")  \n",
    "          \n",
    "read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  writefile file txt\\nthis is the first word \\nthis is the second text  hello  how are you \\nthis is the third  this is it now \\nthis is the algorithm enticed for hashing\\nhashing insn t performed linearly on large datasets '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read=read.lower()                    \n",
    "read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/prayag/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/prayag/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['writefile', 'file', 'txt', 'first', 'word', 'second', 'text', 'hello', 'third', 'algorithm', 'enticed', 'hashing', 'hashing', 'insn', 'performed', 'linearly', 'large', 'datasets']\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    # this will convert\n",
    "    # the word into tokens\n",
    "    text_tokens = word_tokenize(read)\n",
    "  \n",
    "tokens_without_sw = [\n",
    "    word for word in text_tokens if not word in stopwords.words()]\n",
    "  \n",
    "print(tokens_without_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'writefile': [1],\n",
       " 'file': [1],\n",
       " 'txt': [1],\n",
       " 'first': [2],\n",
       " 'word': [2],\n",
       " 'second': [3],\n",
       " 'text': [3],\n",
       " 'hello': [3],\n",
       " 'third': [4],\n",
       " 'algorithm': [5],\n",
       " 'enticed': [5],\n",
       " 'hashing': [5, 5, 6, 6],\n",
       " 'insn': [6],\n",
       " 'performed': [6],\n",
       " 'linearly': [6],\n",
       " 'large': [6],\n",
       " 'datasets': [6]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {}\n",
    "  \n",
    "for i in range(line):\n",
    "    check = array[i].lower()\n",
    "    for item in tokens_without_sw:\n",
    "  \n",
    "        if item in check:\n",
    "            if item not in dict:\n",
    "                dict[item] = []\n",
    "  \n",
    "            if item in dict:\n",
    "                dict[item].append(i+1)\n",
    "  \n",
    "dict"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
